# -*- coding: utf-8 -*-
"""FaceRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OFtVkNICTtUx9V2GwPJ8tukwwokeL7Vx
"""

import numpy as np
import cv2
import tensorflow as tf
from matplotlib import pyplot as plt
#from google.colab.patches import cv2_imshow

"""Metodo di Cascades Classification:

https://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_Image_Object_Detection_Face_Detection_Haar_Cascade_Classifiers.php
"""

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
#eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')


"""I take the already trained model from the drive and I compile it"""

model = tf.keras.models.load_model('D:/Project_DF/Vception_model_mio.h5')

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='adam',
              metrics=["accuracy"])

#I associate names to the numbers of the labels to understand which celebrity I am talking about
label_ids = {'Adam Sandler': 0, 'Alyssa Milano': 1, 'Bruce Willis': 2, 'Denise Richards': 3, 'George Clooney': 4, 'Gwyneth Paltrow': 5, 'Hugh Jackman': 6, 'Jason Statham': 7, 'Jennifer Love Hewitt': 8, 'Lindsay Lohan': 9, 'Mark Ruffalo': 10, 'Robert Downey Jr': 11, 'Will Smith': 12}
class_names = {value:key for key, value in label_ids.items()}
print(class_names[0])


"""Face Prediction

Simple example of how the cascade classifier work
"""


video = cv2.VideoCapture('D:/Project_DF/hugh.mp4') 

length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
print( "frames number:", length )

for it in range(20): #From the first to the last frame
  success, img = video.read() #returns is a boolean (True/False) and image content
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  #Use cascade to detect faces
  faces = face_cascade.detectMultiScale(gray, 1.1, 4)

  for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    #RESIZE, take the faces and put the same shape of those used for the model
    roi_color=cv2.resize(roi_color,(180,180))
    roi_color = np.asarray(roi_color).astype(float)
    roi_color = roi_color/255      
    roi_color = tf.convert_to_tensor(roi_color, dtype=tf.float32)
    #tf.reshape(roi_color, [1,180,180,3])
    #END RESIZE
    prediction = model.predict(tf.reshape(roi_color, [1,180,180,3]))
    ind = np.argmax(prediction)
    print("Actor number: ", ind, "name: ", class_names[ind])


  cv2.imshow("img", img)

video.release()





