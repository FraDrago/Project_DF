# -*- coding: utf-8 -*-
"""Model_pre-trained-Xception.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_CFGbhDM7HSgL0Jr90rf25-kP5CuQXF5
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization,ZeroPadding2D, MaxPool2D


from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator



import os
import cv2

train_path="C:/Users/Franc/OneDrive/Desktop/PROGETTO/Dataset/PeopleFace"

##I extract images from the folders and create the dataset train_x


img1 = cv2.imread('D:/Project_DF/FaceRecogRefSoft/croppedfaces/George Clooney/1.jpg')
img2 = cv2.imread('D:/Project_DF/FaceRecogRefSoft/data/PeopleFace/George Clooney/newcpp_0.jpg')
print(img1.shape)
print(img2.shape)



train_datagen = ImageDataGenerator(
        rescale=1./255,
        fill_mode='nearest',
        validation_split=0.2)

test_datagen = ImageDataGenerator(rescale=1 / 255.0)

train_generator = train_datagen.flow_from_directory(
        'D:/Project_DF/FaceRecogRefSoft/croppedfaces',
        target_size=(180, 180),
        batch_size=32,
        class_mode='categorical',
        subset='training') #set as training data

validation_generator = train_datagen.flow_from_directory(
    'D:/Project_DF/FaceRecogRefSoft/croppedfaces', #same directory as training data
    target_size=(180, 180),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=False
    ) #set as validation data

test_generator = test_datagen.flow_from_directory(
    directory='D:/Project_DF/FaceRecogRefSoft/croppedfacesTest',
    target_size=(180, 180),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)



num_classes = 13

#######CREATION OF THE AlexNet MODEL#################
# https://thecleverprogrammer.com/2021/12/13/alexnet-architecture-using-python/
#Instantiation
model = Sequential()
model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation="relu", input_shape=(180, 180, 3)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))
model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))
model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))
model.add(Flatten())
model.add(Dense(4096, activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(13, activation="softmax"))
model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics
=["accuracy"])
model.summary()

from collections import Counter

counter = Counter(validation_generator.classes) 
print("validation_generator.classes", validation_generator.classes)                         
print("counter", counter)                         
max_val = float(max(counter.values()))       
class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()} 
print(class_weights)

callback = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=2)

# train the model on the new data for a few epochs
history = model.fit(
      x=train_generator,
      epochs=10,
      validation_data=validation_generator,
      verbose=1,
      class_weight = class_weights,
      callbacks=[callback])



tf.keras.models.save_model(model, 'D:/Project_DF/AldfsfdsfdsfdexNet_model.h5')


predict=model.predict_generator(test_generator)
y_classes = np.argmax(predict, axis=1)
print(test_generator.classes)

import seaborn as sn
import pandas as pd
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_generator.classes, y_classes)
print(cm)

class_names = ['Adam Sandler','Alyssa Milano', 'Bruce Willis', 'Denise Richards', 'George Clooney', 'Gwyneth Paltrow', 'Hugh Jackman', 'Jason Statham', 'Jennifer Love Hewitt', 'Lindsay Lohan', 'Mark Ruffalo', 'Robert Downey Jr', 'Will Smith']
df_cm = pd.DataFrame(cm, index = class_names, columns = class_names)

sn.set(font_scale=1.0) # Adjust to fit

plt.figure(figsize = (15,10))
sn.heatmap(df_cm, annot=True, cmap='Blues')
plt.axis([-0.5, 13.5, 13.5, -0.5])
plt.title('Confusion Matrix Test Set')
plt.xlabel('Predicted')
plt.ylabel('True')## Display the visualization of the Confusion Matrix.
plt.show()


