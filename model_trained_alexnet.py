# -*- coding: utf-8 -*-
"""Model_Trained_AlexNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sMRwRCjl50abkcRiPgGpXOL1k_epESyy
"""

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from sklearn.utils import shuffle


train_path="C:/Users/Franc/OneDrive/Desktop/PROGETTO/Dataset/PeopleFace"
#test_path="C:/Users/Franc/OneDrive/Desktop/PROGETTO/Dataset/croppedfacesTest"

import cv2
window_name = 'img'
img=cv2.imread('C:/Users/Franc/OneDrive/Desktop/PROGETTO/Dataset/PeopleFace/Adam Sandler/newcpp_1.jpg')
cv2.imshow(window_name, img)
print(img.shape)

import os
import cv2



x_train=[]

for folder in sorted(os.listdir(train_path)):

    sub_path=train_path+"/"+folder
    print(sub_path)

    for img in os.listdir(sub_path):

        image_path=sub_path+"/"+img

        img_arr=cv2.imread(image_path)

        img_arr=cv2.resize(img_arr,(256,256))

        x_train.append(img_arr)

train_x=np.array(x_train)

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'sparse')

train_y=training_set.classes

print("train_y shape: ", train_y.shape)
print(type(train_y))

label_ids= training_set.class_indices
print(label_ids)

print(train_y.shape)
print(train_x.shape)

def plot_images(images, labels, predictions=None, class_names=None):
    assert len(images) == len(labels) == 9
    
    # Create figure with 3x3 sub-plots.
    fig, axes = plt.subplots(3, 3, figsize=(20, 20))
    fig.subplots_adjust(hspace=0.3, wspace=0.3)
    
    for i, ax in enumerate(axes.flat):
        
        # Plot image.
        ax.imshow(images[i].squeeze(), cmap='gray')
        
        # Show true and predicted classes.
        if predictions is None:
            xlabel = "True: {0}".format(class_names[int(labels[i])])
        else:
            xlabel = "True: {0}, Pred: {1}".format(class_names[int(labels[i])],
            class_names[int(predictions[i].argmax())])

        ax.set_xlabel(xlabel)
        
        # Remove ticks from the plot.
        ax.set_xticks([])
        ax.set_yticks([])
    
    # Ensure the plot is shown correctly with multiple plots
    # in a single Notebook cell.
    plt.show()

class_names = {value:key for key, value in label_ids.items()}
plot_images(  #plot image in BGR format
    train_x[[1, 300, 600, 900, 1200, 1500, 1800, 2100, 2400]],
    train_y[[1, 300, 600, 900, 1200, 1500, 1800, 2100, 2400]],
    predictions=None,
    class_names=class_names
)

"""**Model**

Implement AlexNet: https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/

"""

#shuffle sets using the shuffle function from sklearn (provided above)
train_x, train_y = shuffle(train_x, train_y, random_state=1)
#create test set
from sklearn.model_selection import train_test_split
train_images, test_images, train_labels, test_labels = train_test_split(train_x, train_y, test_size=0.33, random_state=1)

#train_labels = train_y
#train_images = train_x


# Normalization
train_images = train_images / 255.0
test_images = test_images/255.0
################# code here ###################

#Onehot Encoding the labels.
from tensorflow.keras.utils import to_categorical
train_labels=to_categorical(train_labels)

# Number of samples and image dimension (images are squared)
num_samples = train_x.shape[0]
img_shape = train_x.shape[1]

print(num_samples)
print(img_shape)

#Importing library
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization

np.random.seed(1000)

#Instantiation
AlexNet = Sequential()

#1st Convolutional Layer
AlexNet.add(Conv2D(filters=96, input_shape=(img_shape,img_shape,3), kernel_size=(11,11), strides=(4,4), padding='same')) #insert input_shape
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

#2nd Convolutional Layer
AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

#3rd Convolutional Layer
AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))

#4th Convolutional Layer
AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))

#5th Convolutional Layer
AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

#Passing it to a Fully Connected layer
AlexNet.add(Flatten())
# 1st Fully Connected Layer
AlexNet.add(Dense(4096, input_shape=(32,32,3,)))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
# Add Dropout to prevent overfitting
AlexNet.add(Dropout(0.4))

#2nd Fully Connected Layer
AlexNet.add(Dense(4096))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
#Add Dropout
AlexNet.add(Dropout(0.4))

#3rd Fully Connected Layer
AlexNet.add(Dense(1000))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('relu'))
#Add Dropout
AlexNet.add(Dropout(0.4))

#Output Layer
AlexNet.add(Dense(13))
AlexNet.add(BatchNormalization())
AlexNet.add(Activation('softmax'))

AlexNet.compile(loss="sparse_categorical_crossentropy",
              optimizer='adam',
              metrics=["accuracy"])

#Model Summary
AlexNet.summary()


history = AlexNet.fit(train_images, train_labels, 
                    batch_size = 128, epochs=30, validation_split = 0.2)



#test_images test_labels

test_loss, test_acc = AlexNet.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

print("test_images type: ", type(test_images))
print("test_labels type: ", type(test_labels))
print("test_images shape: ", test_images.shape)
print("test_labels shape: ", test_labels.shape)

plot_images(test_images[:9], test_labels[:9], AlexNet.predict(test_images[:9]), class_names)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
print_confusion_matrix_pandas(AlexNet, test_images, test_labels)


print(confusion_matrix(y_pred,test_y))

tf.keras.models.save_model(AlexNet, 'C:/Users/Franc/OneDrive/Desktop/PROGETTO/AlexNet_Classifier_retrain.h5')

